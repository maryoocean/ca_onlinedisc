<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="429689730.0" index="1" link="https://www.reddit.com//r/changemyview/comments/73tqpu/cmv_in_the_future_we_should_have_a_privacyfocused/">
    <title>CMV: In the future, we should have a privacy-focused AI research initiative to identify and end violence and crime.</title>
    <original_poster>AnimeVRexpert</original_poster>
    <original_post>What I mean is that in 5-10 years(or more), when AI is advanced enough to identify and understand with 99.9%+ accuracy exactly what people are doing, we should have them monitoring us worldwide, of course without any human being able to access the recordings. Why?
                                                                                               I 
I can't see many disadvantages to this if done right.
1- Crime would be 90%+ reduced and everyone enjoys a peaceful life because as soon as a crime happens, police would be notified instantly or maybe the AI itself could handle it.

2- Privacy will not only be maintained, it will be increased since there will be fewer excuses for human surveillance.

3- End of terrorism since AI would predict the act before it happens

4- AI could predict suicides and give statistics like "people are 30% happier in the UK" or something like it, helping the world become a much better place.

5- The possibilities are endless, we could save countless lives and help people live better in unimaginable ways.

Disadvantages:

People seem to be against this idea, I [posted a comment](https://www.reddit.com/r/news/comments/73r0uu/active_shooter_at_mandalay_bay_casino_in_las_vegas/dnswcz3/) about the recent tragedy that happened in LA and got massively downvoted(Maybe the part about the drones contributed, what I meant was an AI controlled pacifist drone that would only use tranquilizers so no one gets hurt), this means my view is probably wrong, and I realized now is a perfect time to use CMV.

Would appreciate if you could tell me why my view is wrong or maybe I just presented it the wrong way in the comment.     </original_post>
    </submission>
  <comment id="29737647737.0" user="guyawesome1" delta="False">
    <text>
What happens if the AI is wrong

I don't believe we should create AI because it will contribute to the technological singularity 

If you don't know what that is it is the point when technology is self progressing faster than we (humans) are progressing it

This is bad because we have lost control over where it will go</text>
    </comment>
  <comment id="29737687976.0" user="AnimeVRexpert" delta="False">
    <text>There are already initiatives to prevent AIs from turning bad and if companies like Open AI are successful, ultimately the AIs will have positive values and act only in benefit of humankind.</text>
    </comment>
  <comment id="29737782830.0" user="A_Soporific" delta="True">
    <text>There's a logic puzzle to this.

There's something called the agent-principal problem. As long as the agent knows things that the principal doesn't then there's no way to ensure that the agent is really acting in the best interests of the principal how the principal would define it.

Just having positive values and wanting to benefit humankind doesn't mean that they will be doing things in a way that's acceptable to us. For example, the AI might decide that removing someone from the house might be beneficial to humanity as a whole because of some unexpressed genetic predisposition to violence. You know, something that looks really bad but we should just trust it even though we're sacrificing one innocent person for the greater good. Or, it might just be a bug that develops in the code and that sacrifice and suffering is really unnecessary. We, as average persons, can't tell the difference between those two cases.

As it stand, we are operating on a premise that permits some crime to prevent unjust punishments on the innocent that's only partially successful. The AI might err on the other side, taking the line that preventative punishment is acceptable or even a positive good. I, personally, don't want to be in that world. But, if the benevolent and (mostly) positive AIs decide otherwise then would it even be possible to accommodate me or would I have to be removed? Consistency and predictable results are essential to a properly functioning legal system. I have to know that something is illegal in order to avoid it and if something is illegal but unenforced then I have to know that as well. If I do something and the legal response is not at all what I expect then we have a problem. The preventative function of punishment isn't working, or the arbitrary enforcement has signaled me bad information or whatever. Very often pursuing two strategies spoils both.

But, on a deeper level, this looks like a "enlightened despotism" argument. That if you have an enlightened and just ruler who has literally all the power and authority and no one can get in the way then that's the best government. As long as the ruler is perfect and infallible and just then I guess the argument works... but it doesn't work in practice for a variety of reasons. One of the big ones is that people rip those systems apart even if they are right but don't communicate how and why they are right in a way that the average person buys. But the big reason I'm against those systems and will be forever is that it requires perfection. We will never have perfection. An infinite number of AI generations won't get us to perfection, and what is "right" will be constantly changing. At best, we'll have an AI that's chasing an ever-shifting mix of needs and values that overshoots one way before correcting the other way. At worst, the AI screws up (probably because a person screwed up) and we're stuck in a regular old despotic political system.

I prefer separated powers. The sort of thing that requires compromise and an acknowledgement that those involved aren't perfect and are representing different acceptable paths forward. The more power reserved for the individual to make the decision that's right for them the better. This often isn't what's best for humanity, but we can get pretty close by manipulating it through taxation and regulation.</text>
    </comment>
  </thread>
