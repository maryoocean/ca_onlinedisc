<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="2050475588.0" index="3" link="https://www.reddit.com//r/changemyview/comments/xwst38/cmv_the_only_difference_between_ai_digital_life/">
    <title>CMV: The only difference between AI (digital) life and human (physical) life is the material which sustains it</title>
    <original_poster>CarpeBedlam</original_poster>
    <original_post>To be clear, I’m talking about a theoretical AI which is designed specifically to be indistinguishable from a human, and accomplishes that goal. Also, I don’t necessarily mean an android that is physically equivalent (e.g. Ash from “Alien”), but just a digital consciousness living in a computer which is capable of replicating human behavior. At that point, I’m struggling to find a difference between the two that isn’t solely about the material required to sustain the life (blood, tissue, etc. for human life, silicon, copper, etc. for AI life).</original_post>
    </submission>
  <comment id="40832752322.0" user="jatjqtjat" delta="True">
    <text>theoretically i could create what you are talking about with just a huge conditional statement.

If user says "hello" responded with "Hi"

If user says "Good day" respond with "Nice weather"

and you could make those conditional statements longer to remember what the user had said previous.  billions and billions and trillions and trillions of condition statements.  

with enough conditionals I would eventually replicate human behavior sufficiently well.  But probably this thing would not be conscious and certainly it would be different then a human.

But we don't actually know what causes humans to be conscious.  We know our decision making is powered not by a bunch of conditional statements but rather by a neural network.  But we don't know why an neural network would give rise to the type of consciousness experienced by humans.  we don't even know if a neural network gives rise to consciousness.

like our basic AI with countless pre-programmed conditions, a neural network based IA might also lack consciousness.  Since we don't know what causes consciousness we cannot say with confidence.

We already have neural networks, they are just simple.  It looks like the most powerful computer in the world simulates about 80k neurons and an ant brain has 250k.  So the words biggest computer is about 1/3rd as smart and an ant.  I think at that scope we would say with confidence that while an ant might have consciousness our super computer certainly does not.  But again its not clear if non-humans are conscious or if our primitive neural networks are, because we don't really understand what consciousness is.

besides the complex problem of conscious there is a much simpler difference between artificial and natural intelligence.  All natural life wants to continue to be alive.  All life strives to survive.  but we would have no reason to give our AI this desire.  There is no reason why we'd want our AI to be concerned with its survival in the world.  of course we see this in current AI.  An AI that plays chess or generates artistic pictures does not care if you delete it.   Our AI is unlikely to have any survival instinct.  Rather it will just get trained to perform whatever task we are concerned with.  Tesla's want to avoid car crashes, but they don't try to avoid being deleted.  The AI is concerned with the safety of the car and driver, not with the safety of itself.</text>
    </comment>
  </thread>
