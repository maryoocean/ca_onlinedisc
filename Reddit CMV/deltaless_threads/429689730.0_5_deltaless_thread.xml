<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="429689730.0" index="5" link="https://www.reddit.com//r/changemyview/comments/73tqpu/cmv_in_the_future_we_should_have_a_privacyfocused/">
    <title>CMV: In the future, we should have a privacy-focused AI research initiative to identify and end violence and crime.</title>
    <original_poster>AnimeVRexpert</original_poster>
    <original_post>What I mean is that in 5-10 years(or more), when AI is advanced enough to identify and understand with 99.9%+ accuracy exactly what people are doing, we should have them monitoring us worldwide, of course without any human being able to access the recordings. Why?
                                                                                               I 
I can't see many disadvantages to this if done right.
1- Crime would be 90%+ reduced and everyone enjoys a peaceful life because as soon as a crime happens, police would be notified instantly or maybe the AI itself could handle it.

2- Privacy will not only be maintained, it will be increased since there will be fewer excuses for human surveillance.

3- End of terrorism since AI would predict the act before it happens

4- AI could predict suicides and give statistics like "people are 30% happier in the UK" or something like it, helping the world become a much better place.

5- The possibilities are endless, we could save countless lives and help people live better in unimaginable ways.

Disadvantages:

People seem to be against this idea, I [posted a comment](https://www.reddit.com/r/news/comments/73r0uu/active_shooter_at_mandalay_bay_casino_in_las_vegas/dnswcz3/) about the recent tragedy that happened in LA and got massively downvoted(Maybe the part about the drones contributed, what I meant was an AI controlled pacifist drone that would only use tranquilizers so no one gets hurt), this means my view is probably wrong, and I realized now is a perfect time to use CMV.

Would appreciate if you could tell me why my view is wrong or maybe I just presented it the wrong way in the comment.     </original_post>
    </submission>
  <comment id="29737843593.0" user="BolshevikMuppet" delta="False">
    <text>That kind of gets to the question of (a) what privacy is meant to do, and (b) what could be done to prevent crimes before they happen, and (c) how would one ensure that humans can't corrupt the system.

I'll go in order:

(A).  What is privacy if not the ability to keep some things secret even against being profiled by a machine rather than a person?  Even ignoring that an AI system sufficiently complex to do what you demand would be effectively a person, the general understanding of privacy isn't just "I don't want human beings to know X about me", but rather "I don't want this information being known to *anyone*.

As a subset of this: it's a chilling of what behaviors (including legal behavior) people will be willing to engage in.  People who know their behavior is being recorded act differently than they otherwise do.  This system would *have* to be public knowledge, and would lead to people trying to avoid being viewed with suspicion by the system.

(B).  Okay, let's say it knows that two days from now you're going to commit an act of terrorism.  What legally could be done to stop you?  The AI system can't form the basis for a search warrant (at least in the U.S), since it's fruit of the poisoned tree.  So unless you committed another crime in pursuit of your terrorist acts, what can the authorities do other than violate your due process rights to stop you?

Remember that the 9/11 hijackers had not committed crimes until they...  Did.

(C).  How do you stop an administration from tweaking the AI so that people who write things critical of the government on the internet are also pinged as suspected terrorists?  Not just "well they shouldn't do that" or "we'll try to stop them" or even "the benefits outweigh that risk."

Simply put, many people both now and throughout history have believed that the sacrifice of the freedom to write and speak without government intrusion has been worth more than preventing death.

The existence of a system that can (sight unseen) decide someone is *going* to engage in a terrorist act based on their behavior invites its use against dissidents.  Which (whether it's done or not) impacts people's willingness to dissent.</text>
    </comment>
  </thread>
