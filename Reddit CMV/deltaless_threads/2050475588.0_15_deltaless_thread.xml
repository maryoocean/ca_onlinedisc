<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="2050475588.0" index="15" link="https://www.reddit.com//r/changemyview/comments/xwst38/cmv_the_only_difference_between_ai_digital_life/">
    <title>CMV: The only difference between AI (digital) life and human (physical) life is the material which sustains it</title>
    <original_poster>CarpeBedlam</original_poster>
    <original_post>To be clear, I’m talking about a theoretical AI which is designed specifically to be indistinguishable from a human, and accomplishes that goal. Also, I don’t necessarily mean an android that is physically equivalent (e.g. Ash from “Alien”), but just a digital consciousness living in a computer which is capable of replicating human behavior. At that point, I’m struggling to find a difference between the two that isn’t solely about the material required to sustain the life (blood, tissue, etc. for human life, silicon, copper, etc. for AI life).</original_post>
    </submission>
  <comment id="40830658910.0" user="Inevitable-Year-9422" delta="False">
    <text>I'd say we really won't know what true artificial intelligence is going to look like until we actually build it. My (very sketchy) understanding of AI is that it consists of kind of a strange and unpredictable self-referential loop that keeps building on itself, branching out in peculiar directions at every turn. This loop might produce something recognizably human, or it might produce something entirely alien. My guess is that when true AI emerges, it will probably differ from us in important ways. That doesn't mean it will be any less conscious however, or any less *important*, which is what I think you were really trying to say here. The subjective experience of a computer is no less important than the subjective experience of a human.

In many ways this debate is similar to the "personhood" debate in animal rights. The experience of a human is clearly very different to the experience of an animal. Nevertheless, an intelligent and social animal, such as a chimp or a dolphin, should arguably be considered legally to be a "person", and should be afforded all the legal rights and protections that status affords. The same could be said of a truly conscious AI. The crucial thing here is not really the resemblance it bears to a human. The crucial thing is the capacity it has for subjective experience.</text>
    </comment>
  <comment id="40833444011.0" user="CarpeBedlam" delta="False">
    <text>Yes, you gleaned the unspoken subtext in my line of thought. I didn’t state it outright so as to avoid this turning into a debate on spirituality. The “value” of a subjective, independent experience is an interesting area of philosophy for me, but it’s usually regarding organic non-human life. Presenting the AI as “indistinguishable from human” allowed me to bypass the animal prejudices, but it created a different set of issues that make my premise pure science fiction, unfortunately.</text>
    </comment>
  <comment id="40836562502.0" user="Inevitable-Year-9422" delta="False">
    <text>I agree with you that a computer program that can feel happiness and sadness is, in some sense, a "real person", and should be treated as morally and legally no less important than a physical human. This is one of the really dangerous yet fascinating things about AI research. Fairly soon (in relative historical terms), we might be able to build a computer that has the capacity to suffer. That opens an *enormous* can of worms, ethically-speaking. It will be really interesting to see how society adapts to this change. My hope is that it instills a greater degree of respect for non-human life.</text>
    </comment>
  </thread>
