<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="119312081.0" index="2" link="https://www.reddit.com//r/changemyview/comments/1z19sh/i_wouldnt_mind_artificial_intelligence_replacing/">
    <title>I wouldn't mind artificial intelligence replacing the human race. CMV.</title>
    <original_poster>Sleakne</original_poster>
    <original_post>This is not an incredibly well though out position so plenty of scope to change my view.

I am not debating whether or not it is possible for artificial intelligence to take over just that i'm okay with it if it does happen.

I am imagining a world where we create AI and it becomes smarter and smarter and soon becomes better than us at everything we do. We would be utterly dependent on them because only they would be intelligent enough to manage the incredible complexity of the society they have created.  

It is possible that they might keep the human race going but if they decided to wipe us out (humanely) I'd be okay with that.  They are the next step of our evolution, they are smarter than us in every way and keeping around our limited and flawed physical bodies seem unnecessary.

We can't go on forever, we will eventually die out.  Why fight it. </original_post>
    </submission>
  <comment id="27071382527.0" user="clydem" delta="False">
    <text>The fact, should it come to be, that humans are unnecessary, in any or all  senses, is surely not a good reason to sanction our being exterminated. After all, wouldn't the AI then have roughly the relation to us that we currently have to many of the "lesser" great apes? I don't see that as a license to wipe them out.</text>
    </comment>
  <comment id="27071401645.0" user="Sleakne" delta="False">
    <text>I'm not opposed to them keeping us in a life of luxury either where we pursue pleasure and art and spirituality all day everyday.  I'm just saying that if the human race died out because AI replaced us I wouldn't mourn it's loss and would welcome the machines as our 'children'.</text>
    </comment>
  <comment id="27071475038.0" user="WideEyedLeaver" delta="False">
    <text>Just because something or someone's left behind a 'successor' or whatever, couldn't that thing or person's passing still be a loss?  I mean, sure, you'd have AI and that's super-cool, but you've still lost something, even if you've gained something else.  The strictly 'human' perspective would have been lost, and, however amazing and great these AI 'children' are, I should expect that they won't be the same as humans in terms of viewing the world or valuing things or stuff like that.  </text>
    </comment>
  <comment id="27071481786.0" user="Sleakne" delta="False">
    <text>okay thats a fair point.  In the same way that we keep animals alive like living museums I can't see a reason that they not to keep a small contingent of humans alive.  

But if for whatever reason it was them or us, prehaps we stop making AI because people are scared of the human race dying out, I'd vote for them.</text>
    </comment>
  <comment id="27071494349.0" user="WideEyedLeaver" delta="False">
    <text>Actually, that raises a question I hope you don't mind me asking.  Why does there need to be a reason to keep a sort of being existing?  I would imagine (just off-hand) that it'd be more reasonable to have the default position be to not harm/interfere with/wipe out of existence other sorts of beings, even if they're 'lesser' in some arbitrary metric.  We're precisely 'as evolved' as an orangutan or a turtle or a sunflower, we've just ended up as particularly self-reflective sorts of beings with stellar dexterity.  Basically, the 'advanced' descriptor (EDIT - and the whole sort of associated metric/hierarchy, if that makes sense) is one that seems at least problematic to me.  

EDIT AGAIN - I don't mean to be impolite or anything, just been thinking about this sort of thing.  </text>
    </comment>
  <comment id="27071520109.0" user="Sleakne" delta="False">
    <text>&amp;gt; the default position be to not harm/interfere with/wipe out of existence other sorts of beings

that works up to a point but not everything can live together peacefully.  I don't know if you think viruses are alive but I would happily wipe them out because they hurt us.  I'd probably get rid of certain pests or parasites as well.

I think that is what we would end up being to the AI, parasites, living off them completely, taking up a big chunk of there resources and always reproducing and keeping the cycle going.

As I have said before, if it is possible to keep a small contingent of humans alive then I'm game for that.  If they need to get rid of us for any reason I'm all for that.

Maybe the sun is going to release a form of radiation that would kill them all and the only way they will be able to produce a space ship fast enough to avoid it is to stop looking after humans.  Its hard to think of a better example...</text>
    </comment>
  </thread>
