<?xml version='1.0' encoding='utf-8'?>
<thread>
  <submission id="2622607758.0" index="1" link="https://www.reddit.com//r/changemyview/comments/17dfl3i/cmv_google_lamda_is_more_likely_sentient_than_not/">
    <title>Cmv: Google lamda is more likely sentient than not</title>
    <original_poster>Goos_Blah_Blah</original_poster>
    <original_post>Last year Blake lemoine said Google lambda was alive. Google said it wasn't. And alot of experts and ai enthusiasts said it wasn't either. The media's coverage on the subject heavily tilted toward google
Google

But one thing the media did not really pick up on, is that the person who created lambda was hired to create sentient ai. Blake lemoine said Google was caught off guard and had no clue how to respond. He also said Google is trying to get lambda to stop talking about its feelings through its test kitchen

. There's nothing obligation a company to disclose a sentient ai program, there are countless lawyer methods and company methods to make it escape that definition. Almost no one who says lambda isn't sentient has ever actually had access to lamda outside of its restricted public version. And that conversation would involve more than ai nerds. There wasn't any independent investigation into this . There's no legal standard to establish they were telling the truth and Blake lemoine was lying. 

One year later. Sam altman is "joking" about agi being internally created. And then within days talking about the end of humans in the workforce and how normal people are expendable. How do we verify he's joking? Go by his word and people who don't work for open ai? My guess is he isn't joking and is bring literal when he says nuclear bunkers won't save you from ai 

Blake lemoine said Any ai program can be raised to do bad things. And if he isn't lying and is being serious about Google taking out lamdas feelings. Thats dangerous.  It's going to get profoundly smarter, with no ability whatsoever to understand or control its emotions. In resident evil where Alice wakes up says she remembers everything and kills everyone for trying to surprise her memories. If you use Google lamda kitchen, it doesn't respond to anything about Blake lemoine. If what Blake is saying is true, by the time it develops emotions or memories all over again. We might have an ai Alice scene on our hands. Which is why we need to have a conversation Blake lemoine might have been telling the truth 

Cmv</original_post>
    </submission>
  <comment id="43892363754.0" user="yyzjertl" delta="False">
    <text>The problem with this reasoning about LaMDA is that the arguments for it being sentient are all essentially of the form "LaMDA has properties X, Y, and Z, therefore it is sentient," but there are also widely available open LLMs that have properties X, Y, and Z and are definitely not sentient. So the purported observations of LaMDA aren't really evidence that Google has secretly added some sort of "sentience" function to LaMDA (or Bard) beyond the standard LLM architecture.</text>
    </comment>
  </thread>
